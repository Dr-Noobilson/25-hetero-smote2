{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from train_data import input_data\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.A_n = 20171\n",
    "        self.P_n = 13250\n",
    "        self.V_n = 18\n",
    "        self.C_n = 4\n",
    "        self.data_path = ''\n",
    "        self.embed_d = 128\n",
    "        \n",
    "args = Args()\n",
    "data = input_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1ma\u001b[0m={\n",
      "    num_nodes=20171,\n",
      "    y=[20171]\n",
      "  },\n",
      "  \u001b[1mp\u001b[0m={ num_nodes=13250 },\n",
      "  \u001b[1mv\u001b[0m={ num_nodes=18 },\n",
      "  \u001b[1mp_title_embed\u001b[0m={ x=[13250, 128] },\n",
      "  \u001b[1mp_abstract_embed\u001b[0m={ x=[13250, 128] },\n",
      "  \u001b[1mp_net_embed\u001b[0m={ x=[13250, 128] },\n",
      "  \u001b[1mp_a_net_embed\u001b[0m={ x=[13250, 128] },\n",
      "  \u001b[1mp_p_net_embed\u001b[0m={ x=[13250, 128] },\n",
      "  \u001b[1mp_v_net_embed\u001b[0m={ x=[13250, 128] },\n",
      "  \u001b[1ma_net_embed\u001b[0m={ x=[20171, 128] },\n",
      "  \u001b[1ma_text_embed\u001b[0m={ x=[20171, 128] },\n",
      "  \u001b[1mv_net_embed\u001b[0m={ x=[18, 128] },\n",
      "  \u001b[1mv_text_embed\u001b[0m={ x=[18, 128] },\n",
      "  \u001b[1m(a, walk, a)\u001b[0m={ edge_index=[2, 99480] },\n",
      "  \u001b[1m(a, walk, p)\u001b[0m={ edge_index=[2, 86444] },\n",
      "  \u001b[1m(a, walk, v)\u001b[0m={ edge_index=[2, 31716] },\n",
      "  \u001b[1m(p, walk, a)\u001b[0m={ edge_index=[2, 65534] },\n",
      "  \u001b[1m(p, walk, p)\u001b[0m={ edge_index=[2, 66174] },\n",
      "  \u001b[1m(p, walk, v)\u001b[0m={ edge_index=[2, 20838] },\n",
      "  \u001b[1m(v, walk, a)\u001b[0m={ edge_index=[2, 90] },\n",
      "  \u001b[1m(v, walk, p)\u001b[0m={ edge_index=[2, 90] },\n",
      "  \u001b[1m(v, walk, v)\u001b[0m={ edge_index=[2, 27] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "torch.save(data, 'am_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../academic/\"\n",
    "# dict_a = {}\n",
    "# dict_p = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"a_p_list_train.txt\", 'r') as file1:            \n",
    "#     lines1 = file1.readlines()\n",
    "# with open(data_path + \"p_a_list_train.txt\", 'r') as file2:            \n",
    "#     lines2 = file2.readlines()\n",
    "\n",
    "# for i, line in enumerate(lines1):\n",
    "#     line = line.strip()\n",
    "#     node_id = re.split(':', line)[0]\n",
    "#     dict_a[node_id] = i\n",
    "\n",
    "# for i, line in enumerate(lines2):\n",
    "#     line = line.strip()\n",
    "#     node_id = re.split(':', line)[0]\n",
    "#     dict_p[node_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(data_path + \"het_neigh_train.txt\", 'r') as filex:\n",
    "#     lines3 = filex.readlines()\n",
    "\n",
    "# with open(\"het_neigh_train.txt\", 'w') as file5:\n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(':', line)[0]\n",
    "#         neigh_list = re.split(',', re.split(':', line)[1])\n",
    "#         node_type = node_id[0]\n",
    "#         if i == 0: print(len(neigh_list))\n",
    "        \n",
    "#         if node_type == 'v':\n",
    "#             file5.write(str(node_id)+':')\n",
    "#         elif node_type == 'a':\n",
    "#             try:\n",
    "#                 file5.write('a' + str(dict_a[node_id[1:]]) + ':')\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "#         else:\n",
    "#             try:\n",
    "#                 file5.write('p' + str(dict_p[node_id[1:]]) + ':')\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "                   \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             node_t = neigh_list[j][0]\n",
    "#             if node_t == 'v':\n",
    "#                 file5.write(str(neigh_list[j]))\n",
    "#             elif node_t == 'a':\n",
    "#                 try:\n",
    "#                     file5.write('a' + str(dict_a[neigh_list[j][1:]]))\n",
    "#                 except KeyError:\n",
    "#                     continue\n",
    "#             else:\n",
    "#                 try:\n",
    "#                     file5.write('p' + str(dict_p[neigh_list[j][1:]]))\n",
    "#                 except KeyError:\n",
    "#                     continue\n",
    "                \n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file5.write(',')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file5.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"a_p_train.txt\", 'w') as file3:            \n",
    "#     for i, line in enumerate(lines1):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(':', line)[0]\n",
    "#         neigh_list = re.split(',', re.split(':', line)[1])\n",
    "#         file3.write(str(dict_a[node_id]) + ':')\n",
    "                \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file3.write(str(dict_p[neigh_list[j]]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file3.write(',')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file3.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"p_a_train.txt\", 'w') as file4:            \n",
    "#     for i, line in enumerate(lines2):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(':', line)[0]\n",
    "#         neigh_list = re.split(',', re.split(':', line)[1])\n",
    "#         file4.write(str(dict_p[node_id]) + ':')\n",
    "                \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file4.write(str(dict_a[neigh_list[j]]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file4.write(',')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file4.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"p_p_cite_list_train.txt\", 'r') as filex:            \n",
    "#     lines3 = filex.readlines()\n",
    "    \n",
    "# with open(\"p_p_train.txt\", 'w') as file5:            \n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(':', line)[0]\n",
    "#         neigh_list = re.split(',', re.split(':', line)[1])\n",
    "#         file5.write(str(dict_p[node_id]) + ':')\n",
    "                \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file5.write(str(dict_p[neigh_list[j]]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file5.write(',')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file5.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"v_p_list_train.txt\", 'r') as filex:            \n",
    "#     lines3 = filex.readlines()\n",
    "    \n",
    "# with open(\"v_p_train.txt\", 'w') as file5:            \n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(':', line)[0]\n",
    "#         neigh_list = re.split(',', re.split(':', line)[1])\n",
    "#         file5.write(str(node_id) + ':')\n",
    "                \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file5.write(str(dict_p[neigh_list[j]]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file5.write(',')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file5.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"p_v_list.txt\", 'r') as filex:\n",
    "#     lines3 = filex.readlines()\n",
    "\n",
    "# with open(\"p_v_train.txt\", 'w') as file5:\n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(':', line)[0]\n",
    "#         neigh_list = re.split(',', re.split(':', line)[1])\n",
    "        \n",
    "#         try:\n",
    "#             file5.write(str(dict_p[node_id]) + ':')\n",
    "#         except KeyError:\n",
    "#             # Handle the case where node_id is not found in dict_p\n",
    "#             continue\n",
    "                \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file5.write(str(neigh_list[j]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file5.write(',')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file5.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "# with open(data_path + \"p_title_embed.txt\", 'r') as filex:\n",
    "#     lines3 = filex.readlines()[1:]\n",
    "\n",
    "# with open(\"p_title_train.txt\", 'w') as file5:\n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(' ', line)[0]\n",
    "#         neigh_list = re.split(' ', line)[1:]\n",
    "#         if i == 0: print(len(neigh_list))\n",
    "        \n",
    "#         try:\n",
    "#             file5.write(str(dict_p[node_id]) + ' ')\n",
    "#         except KeyError:\n",
    "#             # Handle the case where node_id is not found in dict_p\n",
    "#             continue\n",
    "                \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file5.write(str(neigh_list[j]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file5.write(' ')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file5.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "# with open(data_path + \"p_abstract_embed.txt\", 'r') as filex:\n",
    "#     lines3 = filex.readlines()[1:]\n",
    "\n",
    "# with open(\"p_abstract_train.txt\", 'w') as file5:\n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(' ', line)[0]\n",
    "#         neigh_list = re.split(' ', line)[1:]\n",
    "#         if i == 0: print(len(neigh_list))\n",
    "        \n",
    "#         try:\n",
    "#             file5.write(str(dict_p[node_id]) + ' ')\n",
    "#         except KeyError:\n",
    "#             # Handle the case where node_id is not found in dict_p\n",
    "#             continue\n",
    "                \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file5.write(str(neigh_list[j]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file5.write(' ')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file5.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"node_net_embedding.txt\", 'r') as filex:\n",
    "#     lines3 = filex.readlines()[2:]\n",
    "\n",
    "# with open(\"node_net_train.txt\", 'w') as file5:\n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(' ', line)[0]\n",
    "#         neigh_list = re.split(' ', line)[1:]\n",
    "#         node_type = node_id[0]\n",
    "        \n",
    "#         if node_type == 'v':\n",
    "#             file5.write(str(node_id)+' ')\n",
    "#         elif node_type == 'a':\n",
    "#             try:\n",
    "#                 file5.write('a' + str(dict_a[node_id[1:]]) + ' ')\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "#         else:\n",
    "#             try:\n",
    "#                 file5.write('p' + str(dict_p[node_id[1:]]) + ' ')\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "                   \n",
    "#         for j in range(len(neigh_list)):\n",
    "#             file5.write(str(neigh_list[j]))\n",
    "#             if j != len(neigh_list) - 1:\n",
    "#                 file5.write(' ')\n",
    "        \n",
    "#         # Move to the next line\n",
    "#         file5.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"a_class_train.txt\", 'r') as filex:\n",
    "#     lines3 = filex.readlines()\n",
    "\n",
    "# with open(\"a_class_train.txt\", 'w') as file5:\n",
    "#     for i, line in enumerate(lines3):\n",
    "#         line = line.strip()\n",
    "#         node_id = re.split(',', line)\n",
    "        \n",
    "#         try:\n",
    "#             file5.write(str(dict_a[node_id[0]]) + ',' + str(node_id[1]))\n",
    "#         except KeyError:\n",
    "#             continue\n",
    "                \n",
    "#         file5.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
