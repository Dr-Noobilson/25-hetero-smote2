{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend([ '../', '../../', '../../..'])\n",
    "import torch\n",
    "import dataloader as dl\n",
    "from args import Args\n",
    "# from model import Het_ConEn, Het_NetEn, EdgePredictor, Het_classify\n",
    "from model_magnn import MAG_ConEn, MAG_NetEn, EdgePredictor, MAG_classify\n",
    "from train2 import train_smote\n",
    "\n",
    "# Set device to GPU if available, else use CPU\n",
    "args = Args()\n",
    "args.dblp()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('../../data/dblp_data.pt')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['p','walk','a'].edge_index)\n",
    "device = args.device\n",
    "# data = data.to(device)\n",
    "\n",
    "# Send all x tensors to the device\n",
    "data['a']['x'] = data['a']['x'].to(device)\n",
    "data['p']['x'] = data['p']['x'].to(device)\n",
    "data['t']['x'] = data['t']['x'].to(device)\n",
    "\n",
    "data['c_embed']['x'] = data['c_embed']['x'].to(device)\n",
    "\n",
    "# Send all y tensors to the device\n",
    "data['a']['y'] = data['a']['y'].to(device)\n",
    "\n",
    "data['a', 'walk', 'a']['edge_index'] = data['a', 'walk', 'a']['edge_index'].to(device) \n",
    "data['a', 'walk', 'p']['edge_index'] = data['a', 'walk', 'p']['edge_index'].to(device)\n",
    "data['a', 'walk', 't']['edge_index'] = data['a', 'walk', 't']['edge_index'].to(device)\n",
    "data['a', 'walk', 'c']['edge_index'] = data['a', 'walk', 'c']['edge_index'].to(device)\n",
    "\n",
    "data['p', 'walk', 'a']['edge_index'] = data['p', 'walk', 'a']['edge_index'].to(device)\n",
    "data['p', 'walk', 'p']['edge_index'] = data['p', 'walk', 'p']['edge_index'].to(device)\n",
    "data['p', 'walk', 't']['edge_index'] = data['p', 'walk', 't']['edge_index'].to(device)\n",
    "data['p', 'walk', 'c']['edge_index'] = data['p', 'walk', 'c']['edge_index'].to(device)\n",
    "\n",
    "data['t', 'walk', 'a']['edge_index'] = data['t', 'walk', 'a']['edge_index'].to(device)\n",
    "data['t', 'walk', 'p']['edge_index'] = data['t', 'walk', 'p']['edge_index'].to(device)\n",
    "data['t', 'walk', 't']['edge_index'] = data['t', 'walk', 't']['edge_index'].to(device)\n",
    "data['t', 'walk', 'c']['edge_index'] = data['t', 'walk', 'c']['edge_index'].to(device)\n",
    "\n",
    "data['c', 'walk', 'a']['edge_index'] = data['c', 'walk', 'a']['edge_index'].to(device)\n",
    "data['c', 'walk', 'p']['edge_index'] = data['c', 'walk', 'p']['edge_index'].to(device)\n",
    "data['c', 'walk', 't']['edge_index'] = data['c', 'walk', 't']['edge_index'].to(device)\n",
    "data['c', 'walk', 'c']['edge_index'] = data['c', 'walk', 'c']['edge_index'].to(device)\n",
    "\n",
    "edge_indices = [ data['a', 'walk', 'a'].edge_index, data['a', 'walk', 'p'].edge_index, data['a', 'walk', 't'].edge_index, data['a', 'walk', 'c'].edge_index ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_train_num = dl.train_num(data['a'].y, args.im_class_num, args.class_samp_num[0], args.im_ratio)\n",
    "print(c_train_num, sum(c_train_num))\n",
    "train_idx, val_idx, test_idx, c_num_mat = dl.segregate(data['a'].y, c_train_num, args.seed[1], args)\n",
    "print(\"train_idx: \", train_idx, \"\\n\", len(train_idx))\n",
    "print(\"val_idx: \", val_idx, \"\\n\", len(val_idx))\n",
    "print(\"test_idx: \", test_idx, \"\\n\", len(test_idx))\n",
    "# print(c_num_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAGNN\n",
    "\n",
    "encoder1 = MAG_ConEn(args.embed_dim, args, args.dropout)\n",
    "encoder2 = MAG_NetEn(args.embed_dim, args.dropout)\n",
    "# encoder1 = torch.load('pretrained/encoder1.pth')\n",
    "# encoder2 = torch.load('pretrained/encoder2.pth')\n",
    "classifier = MAG_classify(args.embed_dim, args.nclass, args.dropout)\n",
    "decoder_a = EdgePredictor(args.embed_dim)\n",
    "decoder_p = EdgePredictor(args.embed_dim)\n",
    "decoder_t = EdgePredictor(args.embed_dim)\n",
    "decoder_c = EdgePredictor(args.embed_dim)\n",
    "# decoder_a = torch.load('pretrained/decoder_a.pth')\n",
    "# decoder_p = torch.load('pretrained/decoder_p.pth')\n",
    "# decoder_t = torch.load('pretrained/decoder_t.pth')\n",
    "# decoder_c = torch.load('pretrained/decoder_c.pth')\n",
    "\n",
    "decoder_list = [decoder_a, decoder_p, decoder_t, decoder_c]\n",
    "\n",
    "encoder1.to(device)\n",
    "encoder2.to(device)\n",
    "classifier.to(device)\n",
    "for decoder in decoder_list:\n",
    "    decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HGNN \n",
    "\n",
    "# encoder1 = Het_ConEn(args.embed_dim, args, args.dropout)\n",
    "# encoder2 = Het_NetEn(args.embed_dim, args.dropout)\n",
    "# # encoder1 = torch.load('pretrained/encoder1.pth')\n",
    "# # encoder2 = torch.load('pretrained/encoder2.pth')\n",
    "# classifier = Het_classify(args.embed_dim, args.nclass, args.dropout)\n",
    "# decoder_a = EdgePredictor(args.embed_dim)\n",
    "# decoder_p = EdgePredictor(args.embed_dim)\n",
    "# decoder_t = EdgePredictor(args.embed_dim)\n",
    "# decoder_c = EdgePredictor(args.embed_dim)\n",
    "# # decoder_a = torch.load('pretrained/decoder_a.pth')\n",
    "# # decoder_p = torch.load('pretrained/decoder_p.pth')\n",
    "# # decoder_t = torch.load('pretrained/decoder_t.pth')\n",
    "# # decoder_c = torch.load('pretrained/decoder_c.pth')\n",
    "\n",
    "# decoder_list = [decoder_a, decoder_p, decoder_t, decoder_c]\n",
    "\n",
    "# encoder1.to(device)\n",
    "# encoder2.to(device)\n",
    "# classifier.to(device)\n",
    "# for decoder in decoder_list:\n",
    "#     decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_smote(data, edge_indices, encoder1, encoder2, classifier, decoder_list, \n",
    "            train_idx, val_idx, test_idx, args, os_mode = 'gsm', train_mode = 'preO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_smote(data, edge_indices, encoder1, encoder2, classifier, decoder_list, test_idx, args = args, dataset = 'Test', os_mode = 'no', train_mode = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(decoder_list[0], '../pretrained_magnn/decoder_a.pth')\n",
    "# torch.save(decoder_list[1], '../pretrained_magnn/decoder_p.pth')\n",
    "# torch.save(decoder_list[2], '../pretrained_magnn/decoder_t.pth')\n",
    "# torch.save(decoder_list[3], '../pretrained_magnn/decoder_c.pth')\n",
    "# torch.save(encoder1, '../pretrained_magnn/encoder1.pth')\n",
    "# torch.save(encoder2, '../pretrained_magnn/encoder2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
